{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step0: dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import lxml.etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step1: load data\n",
    "output:  \n",
    "**input_texts**: list of 2085 talk transcriptions (entire text, not tokenized, mixed case, punctuation etc.)  \n",
    "**labels**: corresponding list of 2085 strings containing several keywords each  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset if it's not already there\n",
    "if not os.path.isfile('ted_en-20160408.zip'):\n",
    "    urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract both the texts and the labels from the xml file\n",
    "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
    "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
    "texts = doc.xpath('//content/text()')\n",
    "labels = doc.xpath('//head/keywords/text()')\n",
    "del doc\n",
    "#print(input_texts[0])\n",
    "#print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step2: preprocessing inputs and labels and building embeddings\n",
    "output:  \n",
    "**inputs_train**: list of 1585 tuples of (token_list, label_integer) for training  \n",
    "**inputs_test**: list of 250 tuples of (token_list, label_integer) for testing  \n",
    "**inputs_cv**: list of 250 tuples of (token_list, label_integer) for cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2085"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess the texts: lowercase, remove text in parentheses, remove punctuation, tokenize into words (split on whitespace)\n",
    "#removing text in parentheses\n",
    "input_texts = [re.sub(r'\\([^)]*\\)', '', input_text) for input_text in texts]\n",
    "#lowercase\n",
    "input_texts = [input_text.lower() for input_text in input_texts]\n",
    "#remove punctuation\n",
    "input_texts = [re.sub(r'[^a-z0-9]+', ' ', input_text) for input_text in input_texts]\n",
    "#tokenize into words\n",
    "input_texts = [input_text.split() for input_text in input_texts]\n",
    "len(input_texts)\n",
    "#input_texts[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.   671.5 1343.  2014.5 2686.  3357.5 4029.  4700.5 5372.  6043.5\n",
      " 6715. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADjdJREFUeJzt3X+MZlV9x/H3p4yKP6qLMBC6u+lg3FhME8RM6LYkTcvaVtC4/CENptUt2Wb+oRariaL/NE36hyaNqElDMhHbtbUqQQ0bQ6yEH2n6B9ThRxFcDVtK2elSdqyAtsba0W//mDPpCAPzzO7zzLNznvcrmTz3nnvm3u9ldz979sy9h1QVkqR+/dy4C5AkjZZBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6Serc1CCdkjwO/AD4CbBcVbNJXgt8EZgBHgd+t6qeThLgk8AVwA+BP6iq+1/s/Oecc07NzMyc5C1I0mS67777vltV0xv1Gyjom9+squ+u2b8euKOqPprk+rb/IeByYE/7+hXgxvb5gmZmZlhYWNhEKZKkJP82SL9TmbrZDxxq24eAK9e0f7ZW3APsSHL+KVxHknQKBg36Ar6e5L4kc63tvKp6EqB9ntvadwLH1nzvYmv7GUnmkiwkWVhaWjq56iVJGxp06ubSqjqe5Fzg9iTffpG+WafteUtkVtU8MA8wOzvrEpqSNCIDjeir6nj7PAF8BbgEeGp1SqZ9nmjdF4Hda759F3B8WAVLkjZnw6BP8sokP7+6Dfw28DBwGDjQuh0Abm3bh4H3ZMVe4NnVKR5J0tYbZOrmPOArK09NMgX8XVV9Lck3gJuTHASeAK5q/W9j5dHKo6w8XnnN0KuWJA1sw6CvqseAi9Zp/09g3zrtBVw7lOokSafMN2MlqXMGvSR1zqDXpi0v93ENaVJsZgkECYCpKZifH+015uY27iNpMI7oJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQa9sZ9RLGLpGs3rhMsbadUS+T7BLJ6o0jeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMG/Ta1FQtvubiX1AcXNdumRr2wF7i4l9QLR/SS1DmDXpI6N3DQJzkjyQNJvtr2L0hyb5JHk3wxyUtb+8va/tF2fGY0pUuSBrGZEf11wJE1+x8DbqiqPcDTwMHWfhB4uqpeD9zQ+kmSxmSgoE+yC3gb8Om2H+Ay4JbW5RBwZdve3/Zpx/e1/pKkMRh0RP8J4IPAT9v+2cAzVbX6AN4isLNt7wSOAbTjz7b+PyPJXJKFJAtLS0snWb4kaSMbBn2StwMnquq+tc3rdK0Bjv1/Q9V8Vc1W1ez09PRAxUqSNm+Q5+gvBd6R5ArgTODVrIzwdySZaqP2XcDx1n8R2A0sJpkCXgN8b+iVS5IGsuGIvqo+XFW7qmoGuBq4s6p+D7gLeGfrdgC4tW0fbvu043dW1fNG9JKkrXEqz9F/CHh/kqOszMHf1NpvAs5u7e8Hrj+1EiVJp2JTSyBU1d3A3W37MeCSdfr8CLhqCLVJkobAN2MlqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmD/hQsL2/cZztcQ1LfNrV6pX7W1BTMz4/2GnNzoz2/pP45opekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUuc2DPokZyb5pyT/nOSRJH/W2i9Icm+SR5N8MclLW/vL2v7RdnxmtLcgSXoxg4zo/we4rKouAt4EvDXJXuBjwA1VtQd4GjjY+h8Enq6q1wM3tH6SpDHZMOhrxX+13Ze0rwIuA25p7YeAK9v2/rZPO74vSYZWsSRpUwaao09yRpIHgRPA7cC/AM9U1XLrsgjsbNs7gWMA7fizwNnrnHMuyUKShaWlpVO7C0nSCxoo6KvqJ1X1JmAXcAlw4Xrd2ud6o/d6XkPVfFXNVtXs9PT0oPVKkjZpU0/dVNUzwN3AXmBHkql2aBdwvG0vArsB2vHXAN8bRrGSpM0b5Kmb6SQ72vbLgbcAR4C7gHe2bgeAW9v24bZPO35nVT1vRC9J2hpTG3fhfOBQkjNY+Yvh5qr6apJvAV9I8ufAA8BNrf9NwN8kOcrKSP7qEdQtSRrQhkFfVQ8BF6/T/hgr8/XPbf8RcNVQqpMknTLfjJWkzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM5tGPRJdie5K8mRJI8kua61vzbJ7UkebZ9ntfYk+VSSo0keSvLmUd+EJOmFDTKiXwY+UFUXAnuBa5O8EbgeuKOq9gB3tH2Ay4E97WsOuHHoVUuSBrZh0FfVk1V1f9v+AXAE2AnsBw61boeAK9v2fuCzteIeYEeS84deuSRpIJuao08yA1wM3AucV1VPwspfBsC5rdtO4Niab1tsbZKkMRg46JO8CvgS8L6q+v6LdV2nrdY531yShSQLS0tLg5YhSdqkgYI+yUtYCfnPVdWXW/NTq1My7fNEa18Edq/59l3A8eees6rmq2q2qmanp6dPtn5J0gYGeeomwE3Akar6+JpDh4EDbfsAcOua9ve0p2/2As+uTvFIkrbe1AB9LgXeDXwzyYOt7SPAR4GbkxwEngCuasduA64AjgI/BK4ZasWSpE3ZMOir6h9Zf94dYN86/Qu49hTrkiQNiW/GSlLnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9NImLC9v7/NrMg3ywpSkZmoK5udHd/65udGdW5PLEb0kdc6gl6TOGfSS1DmDXpI6Z9BLUue2fdBvxeNoPvImaTvb9o9XjvpxN/CRN0nb27Yf0UuSXpxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcxsGfZLPJDmR5OE1ba9NcnuSR9vnWa09ST6V5GiSh5K8eZTFS5I2NsiI/q+Btz6n7XrgjqraA9zR9gEuB/a0rzngxuGUKUk6WRsGfVX9A/C95zTvBw617UPAlWvaP1sr7gF2JDl/WMVKkjbvZOfoz6uqJwHa57mtfSdwbE2/xdYmSRqTYf8wNuu01bodk7kkC0kWlpaWhlyGJGnVyQb9U6tTMu3zRGtfBHav6bcLOL7eCapqvqpmq2p2enr6JMuQJG3kZIP+MHCgbR8Abl3T/p729M1e4NnVKR5J0nhMbdQhyeeB3wDOSbII/CnwUeDmJAeBJ4CrWvfbgCuAo8APgWtGULMkaRM2DPqqetcLHNq3Tt8Crj3VoiRJw+ObsZLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNe2iaWl7f3+TU+U+MuQNJgpqZgfn5055+bG925NV6O6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6txIgj7JW5N8J8nRJNeP4hqSts5WvEz1QtcY57V7MfQXppKcAfwl8FvAIvCNJIer6lvDvpakrTHql7XghV/YGue1ezGKEf0lwNGqeqyqfgx8Adg/gutIkgYwiqDfCRxbs7/Y2iRpW+ll2ihVNdwTJlcBv1NVf9j23w1cUlXvfU6/OWD1H0xvAL4z1EJe3DnAd7fweqcL73uyeN/9+8Wqmt6o0ygWNVsEdq/Z3wUcf26nqpoHRjzztr4kC1U1O45rj5P3PVm8b60axdTNN4A9SS5I8lLgauDwCK4jSRrA0Ef0VbWc5I+AvwfOAD5TVY8M+zqSpMGMZD36qroNuG0U5x6SsUwZnQa878nifQsYwQ9jJUmnF5dAkKTOTVTQT+LSDEl2J7kryZEkjyS5btw1baUkZyR5IMlXx13LVkqyI8ktSb7dfu1/ddw1bYUkf9J+nz+c5PNJzhx3TaeDiQn6NUszXA68EXhXkjeOt6otsQx8oKouBPYC107Ifa+6Djgy7iLG4JPA16rql4CLmID/Bkl2An8MzFbVL7PyMMjV463q9DAxQc+ELs1QVU9W1f1t+wes/IGfiDeVk+wC3gZ8ety1bKUkrwZ+HbgJoKp+XFXPjLeqLTMFvDzJFPAK1nmHZxJNUtBP/NIMSWaAi4F7x1vJlvkE8EHgp+MuZIu9DlgC/qpNW306ySvHXdSoVdW/A38BPAE8CTxbVV8fb1Wnh0kK+qzTNjGPHCV5FfAl4H1V9f1x1zNqSd4OnKiq+8ZdyxhMAW8Gbqyqi4H/Brr/mVSSs1j5V/oFwC8Ar0zy++Ot6vQwSUE/0NIMPUryElZC/nNV9eVx17NFLgXekeRxVqbpLkvyt+MtacssAotVtfovt1tYCf7evQX416paqqr/Bb4M/NqYazotTFLQT+TSDEnCylztkar6+Ljr2SpV9eGq2lVVM6z8Wt9ZVRMxuquq/wCOJXlDa9oHTML/D+IJYG+SV7Tf9/uYgB9CD2Ikb8aejiZ4aYZLgXcD30zyYGv7SHt7Wf16L/C5Nqh5DLhmzPWMXFXdm+QW4H5WnjZ7AN+SBXwzVpK6N0lTN5I0kQx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI693//uIJLcepbLAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram over input lengths\n",
    "Y_plot, X_plot = np.histogram([len(text) for text in input_texts], bins=10)\n",
    "print(X_plot)\n",
    "X_plot = np.arange(10)\n",
    "plt.bar(X_plot, +Y_plot, facecolor='#9999ff', edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4474850 tokens in the dataset.\n",
      "There are 18438 tokens that appear only once.\n",
      "There are 18538 unique tokens to remove.\n",
      "It took 0.3660011291503906 seconds to remove all unnecessary items.\n",
      "There are now only 1926086 tokens in the dataset.\n"
     ]
    }
   ],
   "source": [
    "#get list of all words, and feed them into a Counter\n",
    "all_words = [word for input_text in input_texts for word in input_text]\n",
    "print(\"There are {} tokens in the dataset.\".format(len(all_words)))\n",
    "all_words_counter = collections.Counter(all_words)\n",
    "\n",
    "#remove some noise, take away the 100 most common and all words that only appear once\n",
    "most_common_50 = [word for word, count in all_words_counter.most_common(100)]\n",
    "only_once = [word for word, count in all_words_counter.most_common() if count == 1]\n",
    "print(\"There are {} tokens that appear only once.\".format(len(only_once)))\n",
    "\n",
    "to_remove = set(only_once + most_common_50)\n",
    "print(\"There are {} unique tokens to remove.\".format(len(to_remove)))\n",
    "\n",
    "start = time.time()\n",
    "input_texts = [[word for word in input_text if word not in to_remove] for input_text in input_texts]\n",
    "print(\"It took {} seconds to remove all unnecessary items.\".format(time.time()-start))\n",
    "\n",
    "new_all_words = [word for input_text in input_texts for word in input_text]\n",
    "print(\"There are now only {} tokens in the dataset.\".format(len(new_all_words)))\n",
    "\n",
    "#input_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now only 1924 inputs left.\n"
     ]
    }
   ],
   "source": [
    "#remove all inputs that have less than 500 tokens in them\n",
    "inputs = zip(input_texts, labels)\n",
    "inputs = [text_and_labels for text_and_labels in inputs if len(text_and_labels[0]) > 300]\n",
    "print(\"There are now only {} inputs left.\".format(len(inputs)))\n",
    "input_texts, labels = zip(*inputs)\n",
    "input_texts, labels = list(input_texts), list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding every text to the max text length for later batching\n",
    "#l_max = max([len(text) for text in input_texts])\n",
    "#for text in input_texts:\n",
    "#    text += ['<zero_pad>'] * (l_max - len(text))\n",
    "\n",
    "#truncating every text to only the first 500 tokens\n",
    "l_max = 1000\n",
    "input_texts = [text[:l_max] for text in input_texts]\n",
    "input_texts = [(['<zero_pad>'] * (l_max - len(text)) + text) for text in input_texts]\n",
    "\n",
    "#print(input_texts[0][-10:-1])\n",
    "#print(np.mean([len(text) for text in input_texts]) == l_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 3, 5, 0, 0, 0, 0, 5, 0, 3, 2, 5, 0, 0, 3, 0, 5, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess the labels: search for occurences of the keywords \"technology\", \"entertainment\" or \"design\" and build labels\n",
    "label_lookup = ['ooo', 'Too', 'oEo', 'ooD', 'TEo', 'ToD', 'oED', 'TED']\n",
    "for i in range(len(labels)):\n",
    "    ted_labels = ['o', 'o', 'o']\n",
    "    keyword_list = labels[i].split(', ')\n",
    "    if 'technology' in keyword_list:\n",
    "        ted_labels[0] = 'T'\n",
    "    if 'entertainment' in keyword_list:\n",
    "        ted_labels[1] = 'E'\n",
    "    if 'design' in keyword_list:\n",
    "        ted_labels[2] = 'D'\n",
    "    labels[i] = ''.join(ted_labels)\n",
    "    labels[i] = label_lookup.index(labels[i])\n",
    "len(labels)\n",
    "labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35562"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the unique vocabulary lookup\n",
    "vocab_list = list(set([word for input_text in input_texts for word in input_text]))\n",
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "for i, word in enumerate(vocab_list):\n",
    "    word_to_index[word] = i\n",
    "    index_to_word[i] = word\n",
    "input_indices_list = []\n",
    "for input_text in input_texts:\n",
    "    input_indices_list.append([word_to_index[word] for word in input_text])\n",
    "len(vocab_list)\n",
    "#del vocab_list\n",
    "#del input_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load glove word vectors\n",
    "glove = KeyedVectors.load_word2vec_format('glove.6B.50d.w2vformat.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 35562 words\n",
      "found 34558 word vectors, 0.9717676171193971 of our vocabulary\n",
      "missing words e.g. ['capric', 'transgenesis', 'hyowon', 'ledgett', 'oxygenating', 'geomedicine', 'tilonia', 'ecorock', 'orwant', 'nonverbals', 'shinerama', 'demou', 'malem', 'goodest', 'superintelligence', 'trogontherii', 'hanifaru', 'acinus', 'gammaknife', 'hetain', 'resorbing', 'fluctus', 'unfriend', 'feministing', 'horseshoer', 'peripeteia', 'galactosyl', 'autismsees', 'sesfontein', 'repairability', 'humarr', 'sistas', 'moleeds', 'barbaria', 'muthomi', 'physarum', 'polycephalum', 'entropica', 'lenticularis', 'uncopyable', 'strangelets', 'ghonim', 'houris', 'markerless', 'torajans', 'brakarz', 'ursonate', 'flytower', 'sristi', 'bollacker']\n"
     ]
    }
   ],
   "source": [
    "#creating embeddings, checking for each word in the input texts whether it is part of \n",
    "#the glove corpus, if yes intialize that row in the embeddings with the glove value, if\n",
    "#not initialize it uniformly between [-.1, .1]\n",
    "voc_len = len(word_to_index)\n",
    "print(\"vocabulary size: {} words\".format(voc_len))\n",
    "counter = 0\n",
    "not_found_list = []\n",
    "embeddings = np.random.uniform(-.1, .1, size=(voc_len, 50))\n",
    "for word, index in word_to_index.items():\n",
    "    if word in glove.vocab:\n",
    "        counter += 1\n",
    "        embeddings[index] = glove[word]\n",
    "    elif word == '<zero_pad>':\n",
    "        embeddings[index] = np.zeros(50)\n",
    "    else:\n",
    "        not_found_list.append(word)\n",
    "print(\"found {} word vectors, {} of our vocabulary\".format(counter, float(counter)/voc_len))\n",
    "print(\"missing words e.g. {}\".format(not_found_list[0:50]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1540, 192, 192)\n"
     ]
    }
   ],
   "source": [
    "# combining the tokens and labels for each input, then shuffle them and split into train/test/cv\n",
    "#inputs_combined = list(zip(input_indices_list, labels))\n",
    "#shuffle(inputs_combined)\n",
    "#inputs_train = inputs_combined[:1450]\n",
    "#inputs_test = inputs_combined[1450:1550]\n",
    "#inputs_cv = inputs_combined[1550:]\n",
    "#print((len(inputs_train), len(inputs_test), len(inputs_cv)))\n",
    "#print(inputs_train[0])\n",
    "#print([index_to_word[i] for i in inputs_train[0][0]])\n",
    "#print([input_pair[1] for input_pair in inputs_train])\n",
    "\n",
    "#keep the class label distribution intact\n",
    "inputs_combined = list(zip(input_indices_list, labels))\n",
    "inputs_train, inputs_test, inputs_cv = [], [], []\n",
    "for n in range(len(label_lookup)):\n",
    "    inputs_of_curr_class = [inpu for inpu in inputs_combined if inpu[1] == n]\n",
    "    l = len(inputs_of_curr_class)\n",
    "    split1 = round(0.8*l)\n",
    "    split2 = round(0.9*l)\n",
    "    inputs_train.extend(inputs_of_curr_class[:split1])\n",
    "    inputs_cv.extend(inputs_of_curr_class[split1:split2])\n",
    "    inputs_test.extend(inputs_of_curr_class[split2:])\n",
    "\n",
    "shuffle(inputs_train)\n",
    "shuffle(inputs_cv)\n",
    "shuffle(inputs_test)\n",
    "print((len(inputs_train), len(inputs_test), len(inputs_cv)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting a histogram over the label distribution in the entire dataset\n",
    "#as you can see 'ooo' is basically ~50% of the dataset, so an accuracy score\n",
    "#of 50% could be reached by simply learning to predict 'ooo' all the time (not good)\n",
    "Y_plot = np.histogram(labels, bins=8)[0]\n",
    "X_plot = np.arange(8)\n",
    "plt.bar(X_plot, +Y_plot, facecolor='#9999ff', edgecolor='white')\n",
    "for x,y in zip(X_plot,Y_plot):\n",
    "    plt.text(x, y+0.05, label_lookup[x], ha='center', va= 'bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step3: building the tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the tensorflow logistic regression model\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(object):\n",
    "    def __init__(self, lr, activation, train_algo, embeddings, train_embeddings, voc_len, embed_size, batch_size, hidden_units, classes):\n",
    "        #placeholders\n",
    "        #(batch_size left)\n",
    "        self.input_ph = tf.placeholder(tf.int32, shape=(None, None), name='input')\n",
    "        self.labels_ph = tf.placeholder(tf.int32, shape=(None, classes), name='labels')\n",
    "        self.dropout_ph = tf.placeholder(tf.float32, shape=(), name='dropout')  \n",
    "        \n",
    "        #embedding layer\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "            #depending on whether a pre-trained embedding is provided and whether or not\n",
    "            #the embedding should be trainable\n",
    "            if embeddings is not None and train_embeddings is True:\n",
    "                self.L = tf.Variable(embeddings, name=\"L\")\n",
    "            elif embeddings is not None and train_embeddings is False:\n",
    "                self.L = tf.constant(embeddings, name=\"L\")\n",
    "            else:\n",
    "                self.L = tf.Variable(tf.random_uniform([voc_len, embed_size], -1.0, 1.0), name=\"L\")\n",
    "            input_vectors = tf.nn.embedding_lookup(self.L, self.input_ph)\n",
    "            X = tf.squeeze(tf.reduce_mean(input_vectors, axis=1, keep_dims=True), axis=1)\n",
    "        \n",
    "        #network model\n",
    "        with tf.name_scope(\"network\"):\n",
    "            W1 = tf.Variable(tf.random_normal((embed_size, hidden_units), stddev=0.1), name=\"W1\")\n",
    "            b1 = tf.Variable(tf.zeros(hidden_units), name='b1')\n",
    "\n",
    "            self.W2 = tf.Variable(tf.random_normal((hidden_units, classes), stddev=0.1), name=\"W2\")\n",
    "            b2 = tf.Variable(tf.zeros(classes), name='b2')\n",
    "            \n",
    "            if activation == 'relu':\n",
    "                hidden = tf.nn.relu(tf.matmul(tf.cast(X, tf.float32), W1) + b1)\n",
    "            elif activation == 'tanh':\n",
    "                hidden = tf.nn.tanh(tf.matmul(tf.cast(X, tf.float32), W1) + b1)\n",
    "            else:\n",
    "                hidden = tf.nn.sigmoid(tf.matmul(tf.cast(X, tf.float32), W1) + b1)\n",
    "            hidden = tf.nn.dropout(hidden, self.dropout_ph)\n",
    "\n",
    "            output = tf.matmul(hidden, self.W2) + b2\n",
    "            output = tf.nn.dropout(output, self.dropout_ph)\n",
    "            #yhat = tf.nn.softmax(out) #no need to calc whole prob dist if we only want the argmax\n",
    "            self.predictions = tf.argmax(output, axis=1)\n",
    "        \n",
    "        #loss\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            self.losses = tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=self.labels_ph)\n",
    "            l2_loss = tf.nn.l2_loss(W1) + tf.nn.l2_loss(b1) + tf.nn.l2_loss(self.W2) + tf.nn.l2_loss(b2)\n",
    "            self.loss = tf.reduce_mean(self.losses) + (0.01 * l2_loss)\n",
    "            \n",
    "        #acc\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.labels_ph, axis=1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "            \n",
    "        #training operation\n",
    "        with tf.name_scope(\"training\"):\n",
    "            if train_algo == 'adam':\n",
    "                self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss)\n",
    "            elif train_algo == 'adagrad':\n",
    "                self.train_op = tf.train.AdagradOptimizer(lr).minimize(self.loss)\n",
    "            else:\n",
    "                self.train_op = tf.train.GradientDescentOptimizer(lr).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, nn, train_data, cv_data, test_data, batch_size, train_dropout, epochs):\n",
    "        self.nn = nn\n",
    "        self.train_data = train_data\n",
    "        self.cv_data = cv_data\n",
    "        self.test_data = test_data\n",
    "        self.batch_size = batch_size\n",
    "        self.train_dropout = train_dropout\n",
    "        self.epochs = epochs\n",
    "        self.W2, self.collect_preds, self.collect_truth = None, [], []\n",
    "\n",
    "    def _get_data_batch(self, curr_index, batch_size, data):\n",
    "        curr_batch = data[curr_index:curr_index+batch_size]\n",
    "        input_batch_list, labels_batch_list = zip(*curr_batch) #unzip the list of input pair tuples (text, label)\n",
    "        #print([len(text) for text in input_batch_list])\n",
    "        curr_input_batch = np.array(input_batch_list, dtype=np.int32)\n",
    "        one_hot = np.zeros((len(labels_batch_list), classes))            \n",
    "        one_hot[range(len(labels_batch_list)), labels_batch_list] = 1            \n",
    "        curr_labels_batch = one_hot\n",
    "        return curr_input_batch, curr_labels_batch\n",
    "    \n",
    "    def _print_status(self, i, epoch_loss, epoch_train_acc, epoch_cv_acc):\n",
    "        print (\"epoch: {}, epoch train loss: {:.3f}, epoch train accuracy: {:.3f}, epoch cv accuracy: {:.3f} \".\n",
    "               format(i, np.mean(epoch_loss), np.mean(epoch_train_acc), np.mean(epoch_cv_acc)))#, end=\"\\r\")\n",
    "        \n",
    "    def run_epoch(self, sess, i):\n",
    "        self.W2 = None\n",
    "        epoch_loss, epoch_train_acc, epoch_cv_acc = [], [], []\n",
    "        #run training on the train data\n",
    "        curr_index = 0\n",
    "        while curr_index < len(self.train_data):\n",
    "            curr_input_batch, curr_labels_batch = self._get_data_batch(curr_index, self.batch_size, self.train_data)\n",
    "            feed_dict={self.nn.dropout_ph:self.train_dropout, \n",
    "                       self.nn.input_ph:curr_input_batch, \n",
    "                       self.nn.labels_ph:curr_labels_batch}\n",
    "            self.W2, c_loss, c_losses, c_train_acc, _ = sess.run([self.nn.W2, self.nn.loss, self.nn.losses, self.nn.accuracy, self.nn.train_op], feed_dict=feed_dict)\n",
    "            #print(c_losses)\n",
    "            #print(c_loss)\n",
    "            epoch_loss.append(c_loss)\n",
    "            epoch_train_acc.append(c_train_acc)\n",
    "            curr_index += self.batch_size\n",
    "        \n",
    "        #run cross evaluation on the cv data\n",
    "        curr_index = 0\n",
    "        while curr_index < len(self.cv_data):\n",
    "            curr_input_batch, curr_labels_batch = self._get_data_batch(curr_index, self.batch_size, self.cv_data)\n",
    "            feed_dict={self.nn.dropout_ph:1.0, \n",
    "                       self.nn.input_ph:curr_input_batch, \n",
    "                       self.nn.labels_ph:curr_labels_batch}\n",
    "            c_cv_acc = sess.run(self.nn.accuracy, feed_dict=feed_dict)\n",
    "            epoch_cv_acc.append(c_cv_acc)\n",
    "            curr_index += self.batch_size\n",
    "        \n",
    "        self._print_status(i, epoch_loss, epoch_train_acc, epoch_cv_acc)\n",
    "    \n",
    "    def train(self):\n",
    "        print(\"Starting training for {} epochs.\".format(self.epochs))\n",
    "        with tf.Session() as sess:\n",
    "            tf.global_variables_initializer().run()\n",
    "            for i in range(self.epochs):\n",
    "                self.run_epoch(sess, i)\n",
    "            print(\"Done Training.\")\n",
    "            self._test(sess)\n",
    "        \n",
    "    def _test(self, sess):\n",
    "        print(\"Testing the trained model on the test set.\")\n",
    "        #would be better to choose the best model on cv for this instead of simply the one from the last iteration\n",
    "        curr_index = 0\n",
    "        epoch_test_acc = []\n",
    "        while curr_index < len(self.test_data):\n",
    "            curr_input_batch, curr_labels_batch = self._get_data_batch(curr_index, self.batch_size, self.test_data)\n",
    "            feed_dict={self.nn.dropout_ph:1.0, \n",
    "                       self.nn.input_ph:curr_input_batch, \n",
    "                       self.nn.labels_ph:curr_labels_batch}\n",
    "            c_test_acc, test_predictions = sess.run([self.nn.accuracy, self.nn.predictions], feed_dict=feed_dict)\n",
    "            epoch_test_acc.append(c_test_acc)\n",
    "            self.collect_preds.extend(test_predictions)\n",
    "            self.collect_truth.extend(np.argmax(curr_labels_batch, axis=1))\n",
    "            curr_index += self.batch_size\n",
    "        print(\"Test set accuracy: {}\".format(np.mean(epoch_test_acc)))\n",
    "        print(\"Done Testing.\")      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step4: model instantiation, training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 20 epochs.\n",
      "epoch: 0, epoch train loss: 1.874, epoch train accuracy: 0.465, epoch cv accuracy: 0.582 \n",
      "epoch: 1, epoch train loss: 1.621, epoch train accuracy: 0.568, epoch cv accuracy: 0.649 \n",
      "epoch: 2, epoch train loss: 1.511, epoch train accuracy: 0.625, epoch cv accuracy: 0.626 \n",
      "epoch: 3, epoch train loss: 1.409, epoch train accuracy: 0.672, epoch cv accuracy: 0.652 \n",
      "epoch: 4, epoch train loss: 1.388, epoch train accuracy: 0.696, epoch cv accuracy: 0.642 \n",
      "epoch: 5, epoch train loss: 1.267, epoch train accuracy: 0.756, epoch cv accuracy: 0.653 \n",
      "epoch: 6, epoch train loss: 1.251, epoch train accuracy: 0.746, epoch cv accuracy: 0.636 \n",
      "epoch: 7, epoch train loss: 1.226, epoch train accuracy: 0.748, epoch cv accuracy: 0.615 \n",
      "epoch: 8, epoch train loss: 1.188, epoch train accuracy: 0.765, epoch cv accuracy: 0.642 \n",
      "epoch: 9, epoch train loss: 1.209, epoch train accuracy: 0.760, epoch cv accuracy: 0.648 \n",
      "epoch: 10, epoch train loss: 1.193, epoch train accuracy: 0.769, epoch cv accuracy: 0.653 \n",
      "epoch: 11, epoch train loss: 1.153, epoch train accuracy: 0.786, epoch cv accuracy: 0.635 \n",
      "epoch: 12, epoch train loss: 1.142, epoch train accuracy: 0.793, epoch cv accuracy: 0.635 \n",
      "epoch: 13, epoch train loss: 1.135, epoch train accuracy: 0.789, epoch cv accuracy: 0.648 \n",
      "epoch: 14, epoch train loss: 1.099, epoch train accuracy: 0.785, epoch cv accuracy: 0.674 \n",
      "epoch: 15, epoch train loss: 1.141, epoch train accuracy: 0.788, epoch cv accuracy: 0.646 \n",
      "epoch: 16, epoch train loss: 1.109, epoch train accuracy: 0.792, epoch cv accuracy: 0.641 \n",
      "epoch: 17, epoch train loss: 1.127, epoch train accuracy: 0.784, epoch cv accuracy: 0.637 \n",
      "epoch: 18, epoch train loss: 1.134, epoch train accuracy: 0.794, epoch cv accuracy: 0.663 \n",
      "epoch: 19, epoch train loss: 1.093, epoch train accuracy: 0.803, epoch cv accuracy: 0.675 \n",
      "Done Training.\n",
      "Testing the trained model on the test set.\n",
      "Test set accuracy: 0.6357142925262451\n",
      "Done Testing.\n"
     ]
    }
   ],
   "source": [
    "#config\n",
    "embed_size = 50\n",
    "batch_size = 50\n",
    "hidden_units = 50\n",
    "learning_rate = 0.03\n",
    "voc_len = len(word_to_index)\n",
    "classes = len(label_lookup)\n",
    "\n",
    "\n",
    "#instantiate a network\n",
    "#this can now be tested with all kinds of configurations\n",
    "#'tanh', 'adam', dropout of 0.5 and a lr of 0.05 seems to work best for me\n",
    "nn = TextClassifier(\n",
    "    lr=learning_rate,\n",
    "    activation='tanh',\n",
    "    train_algo='adam',\n",
    "    embeddings=embeddings, #or embeddings=None\n",
    "    train_embeddings=True,\n",
    "    voc_len=voc_len,\n",
    "    embed_size=embed_size,\n",
    "    batch_size=batch_size,\n",
    "    hidden_units=hidden_units,\n",
    "    classes=classes\n",
    ")\n",
    "\n",
    "#instantiate a trainer, train the model on the train data and then run the test on the test data\n",
    "trainer = Trainer(\n",
    "    nn=nn,\n",
    "    train_data=inputs_train,\n",
    "    cv_data=inputs_cv,\n",
    "    test_data=inputs_test,\n",
    "    batch_size=batch_size,\n",
    "    train_dropout=0.5,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11fe3bcf8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFptJREFUeJzt3X+UlWW99/H35zCT/NKFwMSDDD4zuXgSmwh1Qj2oRZx41ONSMy1MDMscRT2ZPa3SzirXU7nyFMtQTuUiUWiFeAQzyTjnZErLLMUzIOYP/IHCgQlOjHAwkSh+fJ8/9j08Aw4Ms39w77n4vNaatfd97eu+7y/b8TPXXPu+r1FEYGZm6fqbvAswM7PKctCbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJq8m7AIChQ4dGQ0ND3mWYmfUqy5YteyMi6rrrVxVB39DQQGtra95lmJn1KpL+82D6eerGzCxxDnozs8R1G/SS7pa0UdLzXbz2JUkhaWi2LUl3SFol6feSTqpE0WZmdvAOZo5+DvDPwI87N0oaCXwUWNup+WxgVPZ1CvDD7NHMErNjxw7a2trYvn173qUkr2/fvtTX11NbW1vU/t0GfUQ8Lqmhi5e+B3wZeKhT2/nAj6OwyP1TkgZJGh4RG4qqzsyqVltbG0ceeSQNDQ1IyrucZEUEmzZtoq2tjcbGxqKOUdQcvaTzgD9ExLP7vDQCWNdpuy1rM7PEbN++nSFDhjjkK0wSQ4YMKek3px5fXimpP/CPwKSuXu6ircs/YSWpBWgBOPbYY3tahplVAYf8oVHq+1zMiP44oBF4VtIaoB5YLul/UBjBj+zUtx5Y39VBImJWRDRHRHNdXbfX+5uZWZF6PKKPiOeAd3dsZ2HfHBFvSFoEXCfpPgofwr7p+Xmzw8P3HnmlrMe74aP/q6zHOxgDBw5k69atrF+/ns9//vMsXLhwv31nzJhBS0sL/fv3B+Ccc87h3nvvZdCgQYeq3IPWbdBLmg98GBgqqQ24OSJm76f7YuAcYBWwDfhMmercr3J/c5VLHt+kZvZOu3btok+fPj3a55hjjjlgyEMh6KdMmbIn6BcvXlx0jZXW7dRNRFwSEcMjojYi6vcN+YhoiIg3sucREddGxHER8f6I8LoGZlYxa9as4fjjj2fq1KmMGTOGiy66iG3bttHQ0MA3vvENTj/9dBYsWMBrr73GWWedxcknn8wZZ5zBSy+9BMDq1as57bTT+OAHP8jXvva1vY7b1NQEFH5QfOlLX+L9738/Y8aMYebMmdxxxx2sX7+eCRMmMGHCBKCwlMsbb7wBwG233UZTUxNNTU3MmDFjzzFHjx7NlVdeyfve9z4mTZrEn//8ZwDuuOMOTjjhBMaMGcPkyZPL/j5VxVo3ZmbFevnll5k9ezbjx4/ns5/9LD/4wQ+AwrXnTzzxBAATJ07kzjvvZNSoUSxdupRrrrmGxx57jOuvv55p06bx6U9/mu9///tdHn/WrFmsXr2aZ555hpqaGjZv3szgwYO57bbbWLJkCUOHDt2r/7Jly7jnnntYunQpEcEpp5zChz70IY4++mheffVV5s+fz49+9CM+8YlP8MADDzBlyhRuvfVWVq9ezRFHHMGWLVvK/h55CQQz69VGjhzJ+PHjAZgyZcqecP/kJz8JwNatW/nd737HxRdfzNixY7nqqqvYsKHw0eFvf/tbLrnkEgAuu+yyLo//q1/9iquvvpqamsK4ePDgwQes54knnuBjH/sYAwYMYODAgVx44YX85je/AaCxsZGxY8cCcPLJJ7NmzRoAxowZw6WXXspPfvKTPecpJ4/ozaxX2/fSw47tAQMGALB7924GDRrEihUrDmr/fUVEjy5vLNwv2rUjjjhiz/M+ffrsmbr5xS9+weOPP86iRYv45je/yQsvvFDWwPeI3sx6tbVr1/Lkk08CMH/+fE4//fS9Xj/qqKNobGxkwYIFQCGIn322cK/n+PHjue+++wCYN29el8efNGkSd955Jzt37gRg8+bNABx55JG89dZb7+h/5pln8rOf/Yxt27bx9ttv8+CDD3LGGWfst/7du3ezbt06JkyYwHe+8x22bNnC1q1be/IWdMsjejMri7yuNBs9ejRz587lqquuYtSoUUybNo2ZM2fu1WfevHlMmzaNb33rW+zYsYPJkyfzgQ98gNtvv51PfepT3H777Xz84x/v8vif+9zneOWVVxgzZgy1tbVceeWVXHfddbS0tHD22WczfPhwlixZsqf/SSedxOWXX864ceP27H/iiSfumabZ165du5gyZQpvvvkmEcENN9xQ9ks0daBfMw6V5ubmKPYPj/jySrN8rFy5ktGjR+daw5o1azj33HN5/vl3LK6bnK7eb0nLIqK5u309dWNmljgHvZn1Wg0NDYfFaL5UDnozs8Q56M3MEuegNzNLnIPezCxxvo7ezMpjybfLe7wJN3XbZcuWLdx7771cc801PTr0nDlzmDRpEscccwxQ+FC3tbX1HevWpMIjejPrtbZs2bJnEbPOdu3adcD95syZw/r1Xf5NpCR5RG9mvdaNN97Ia6+9xtixY6mtrWXgwIEMHz6cFStWsHjx4r1uppo+fTpbt26lqamJ1tZWLr30Uvr167dn+YSZM2fy85//nB07drBgwQKOP/74PP9pZeURvZn1WrfeeivHHXccK1as4Lvf/S5PP/00t9xyCy+++OJ+97noootobm5m3rx5rFixgn79+gEwdOhQli9fzrRp05g+ffqh+iccEg56M0vGuHHjaGxsLGrfCy+8ENh7+eBUOOjNLBkdSxMD1NTUsHv37j3b27dvP+C+HUsI9+nTZ89Klalw0JtZr7W/pYIBhg0bxsaNG9m0aRN/+ctfePjhhw9qvxT5w1gzK4+DuByy3IYMGcL48eNpamqiX79+DBs2bM9rtbW1fP3rX+eUU06hsbFxrw9XL7/8cq6++uq9PoxNmZcprhAvU2ypq4Zlig8nFV2mWNLdkjZKer5T23clvSTp95IelDSo02s3SVol6WVJ/7uH/xYzMyuzg5mjnwOctU/bI0BTRIwBXgFuApB0AjAZeF+2zw8k9SlbtWZm1mPdBn1EPA5s3qftlxHR8bH0U0B99vx84L6I+EtErAZWAePKWK+ZVZFqmPo9HJT6PpfjqpvPAv+aPR8BrOv0WlvWZmaJ6du3L5s2bXLYV1hEsGnTJvr27Vv0MUq66kbSPwI7gY4/n64uunX5XSCpBWgBOPbYY0spw8xyUF9fT1tbG+3t7XmXkry+fftSX1/ffcf9KDroJU0FzgUmxv//kd4GjOzUrR7ocuWgiJgFzILCVTfF1mFm+aitrS36LlQ7tIqaupF0FvAV4LyI2NbppUXAZElHSGoERgFPl16mmZkVq9sRvaT5wIeBoZLagJspXGVzBPCIJICnIuLqiHhB0v3AixSmdK6NiAOvF2pmZhXVbdBHxCVdNM8+QP9bgFtKKcrMzMrHa92YmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mlriS/pRgNTh17ay8S9iP6XkXYGYGeERvZpY8B72ZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeK6DXpJd0vaKOn5Tm2DJT0i6dXs8eisXZLukLRK0u8lnVTJ4s3MrHsHM6KfA5y1T9uNwKMRMQp4NNsGOBsYlX21AD8sT5lmZlasboM+Ih4HNu/TfD4wN3s+F7igU/uPo+ApYJCk4eUq1szMeq7YOfphEbEBIHt8d9Y+AljXqV9b1mZmZjkp94ex6qItuuwotUhqldTa3t5e5jLMzKxDsUH/x44pmexxY9beBozs1K8eWN/VASJiVkQ0R0RzXV1dkWWYmVl3ig36RcDU7PlU4KFO7Z/Orr45FXizY4rHzMzy0e3qlZLmAx8GhkpqA24GbgXul3QFsBa4OOu+GDgHWAVsAz5TgZrNzKwHug36iLhkPy9N7KJvANeWWpSZmZWP74w1M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0tcSUEv6QZJL0h6XtJ8SX0lNUpaKulVSf8i6V3lKtbMzHqu6KCXNAL4PNAcEU1AH2Ay8E/A9yJiFPDfwBXlKNTMzIpT6tRNDdBPUg3QH9gAfARYmL0+F7igxHOYmVkJig76iPgDMB1YSyHg3wSWAVsiYmfWrQ0YUWqRZmZWvFKmbo4GzgcagWOAAcDZXXSN/ezfIqlVUmt7e3uxZZiZWTdKmbr5O2B1RLRHxA7gp8DfAoOyqRyAemB9VztHxKyIaI6I5rq6uhLKMDOzAykl6NcCp0rqL0nAROBFYAlwUdZnKvBQaSWamVkpSpmjX0rhQ9flwHPZsWYBXwG+KGkVMASYXYY6zcysSDXdd9m/iLgZuHmf5teBcaUc18zMysd3xpqZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJa6koJc0SNJCSS9JWinpNEmDJT0i6dXs8ehyFWtmZj1X6oj+duDfIuJ44APASuBG4NGIGAU8mm2bmVlOig56SUcBZwKzASLirxGxBTgfmJt1mwtcUGqRZmZWvFJG9O8B2oF7JD0j6S5JA4BhEbEBIHt8dxnqNDOzIpUS9DXAScAPI+JE4G16ME0jqUVSq6TW9vb2EsowM7MDKSXo24C2iFiabS+kEPx/lDQcIHvc2NXOETErIpojormurq6EMszM7ECKDvqI+C9gnaT3Zk0TgReBRcDUrG0q8FBJFZqZWUlqStz/H4B5kt4FvA58hsIPj/slXQGsBS4u8RxmZlaCkoI+IlYAzV28NLGU45qZWfn4zlgzs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8SVHPSS+kh6RtLD2XajpKWSXpX0L5LeVXqZZmZWrHKM6K8HVnba/ifgexExCvhv4IoynMPMzIpUUtBLqgf+Hrgr2xbwEWBh1mUucEEp5zAzs9KUOqKfAXwZ2J1tDwG2RMTObLsNGFHiOczMrARFB72kc4GNEbGsc3MXXWM/+7dIapXU2t7eXmwZZmbWjVJG9OOB8yStAe6jMGUzAxgkqSbrUw+s72rniJgVEc0R0VxXV1dCGWZmdiBFB31E3BQR9RHRAEwGHouIS4ElwEVZt6nAQyVXaWZmRavEdfRfAb4oaRWFOfvZFTiHmZkdpJruu3QvIn4N/Dp7/jowrhzH7dWWfDvvCvZvwk15V2Bmh5DvjDUzS5yD3swscWWZurF3evL1TXmXsF+nTci7AjM7lDyiNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxRQe9pJGSlkhaKekFSddn7YMlPSLp1ezx6PKVa2ZmPVXKiH4n8H8iYjRwKnCtpBOAG4FHI2IU8Gi2bWZmOSk66CNiQ0Qsz56/BawERgDnA3OzbnOBC0ot0szMileWOXpJDcCJwFJgWERsgMIPA+Dd5TiHmZkVp+SglzQQeAD4QkT8qQf7tUhqldTa3t5eahlmZrYfJQW9pFoKIT8vIn6aNf9R0vDs9eHAxq72jYhZEdEcEc11dXWllGFmZgdQylU3AmYDKyPitk4vLQKmZs+nAg8VX56ZmZWqpoR9xwOXAc9JWpG1fRW4Fbhf0hXAWuDi0ko0M7NSFB30EfEEoP28PLHY45qZWXn5zlgzs8Q56M3MElfKHL1ZeS35dt4VdG3CTXlXYFYSj+jNzBLnoDczS5ynbg5HVTpF8uTrm/IuoUunTci7ArPSeERvZpY4j+jNeqsq/c3MH15XH4/ozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS5ztjD0PVuqaMmVWGR/RmZolz0JuZJc5TN2bdqdbFw6xnqvW/4yFYBK5iI3pJZ0l6WdIqSTdW6jxmZnZgFRnRS+oDfB/4KNAG/IekRRHxYiXOZ2ZVpFpHzoexSk3djANWRcTrAJLuA84HHPRmZVKtV0+d9p4heZdg+6jU1M0IYF2n7baszczMDrFKjejVRVvs1UFqAVqyza2SXi7yXEOBN4rct5KqtS6o3tpcV8+4rp6p0rq+Wkpd//NgOlUq6NuAkZ2264H1nTtExCxgVqknktQaEc2lHqfcqrUuqN7aXFfPuK6eOZzrqtTUzX8AoyQ1SnoXMBlYVKFzmZnZAVRkRB8ROyVdB/w70Ae4OyJeqMS5zMzswCp2w1RELAYWV+r4nZQ8/VMh1VoXVG9trqtnXFfPHLZ1KSK672VmZr2W17oxM0tcrw76alxmQdLdkjZKej7vWjqTNFLSEkkrJb0g6fq8awKQ1FfS05Kezer6v3nX1JmkPpKekfRw3rV0kLRG0nOSVkhqzbueDpIGSVoo6aXs++y0Kqjpvdn71PH1J0lfyLsuAEk3ZN/zz0uaL6lvxc7VW6dusmUWXqHTMgvAJXkvsyDpTGAr8OOIaMqzls4kDQeGR8RySUcCy4ALquD9EjAgIrZKqgWeAK6PiKfyrKuDpC8CzcBREXFu3vVAIeiB5oioqmvCJc0FfhMRd2VX2/WPiC1519Uhy4w/AKdExH/mXMsICt/rJ0TEnyXdDyyOiDmVOF9vHtHvWWYhIv4KdCyzkKuIeBzYnHcd+4qIDRGxPHv+FrCSKrhbOQq2Zpu12VdVjD4k1QN/D9yVdy3VTtJRwJnAbICI+Gs1hXxmIvBa3iHfSQ3QT1IN0J997jUqp94c9F5moUiSGoATgaX5VlKQTY+sADYCj0REVdQFzAC+DOzOu5B9BPBLScuyO8yrwXuAduCebKrrLkkD8i5qH5OB+XkXARARfwCmA2uBDcCbEfHLSp2vNwd9t8ss2DtJGgg8AHwhIv6Udz0AEbErIsZSuIN6nKTcp7wknQtsjIhledfShfERcRJwNnBtNl2YtxrgJOCHEXEi8DZQFZ+bAWRTSecBC/KuBUDS0RRmIBqBY4ABkqZU6ny9Oei7XWbB9pbNgT8AzIuIn+Zdz76yX/V/DZyVcykA44Hzsvnw+4CPSPpJviUVRMT67HEj8CCFacy8tQFtnX4bW0gh+KvF2cDyiPhj3oVk/g5YHRHtEbED+Cnwt5U6WW8Oei+z0APZh56zgZURcVve9XSQVCdpUPa8H4X/AV7KtyqIiJsioj4iGih8bz0WERUbcR0sSQOyD9PJpkYmAblf4RUR/wWsk/TerGki1bUs+SVUybRNZi1wqqT+2f+bEyl8blYRvfZPCVbrMguS5gMfBoZKagNujojZ+VYFFEaolwHPZfPhAF/N7mDO03BgbnZFxN8A90dE1VzKWIWGAQ8WsoEa4N6I+Ld8S9rjH4B52cDrdeAzOdcDgKT+FK7OuyrvWjpExFJJC4HlwE7gGSp4h2yvvbzSzMwOTm+eujEzs4PgoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PE/T/B22rvAZqFSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.arange(9)\n",
    "plt.hist(np.array(trainer.collect_preds), bins, alpha=0.5, label='predictions')\n",
    "plt.hist(np.array(trainer.collect_truth), bins, alpha=0.5, label='truth')\n",
    "plt.legend(loc='upper right')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([107,  37,  13,  15,   3,  12,   2,   3]),\n",
       " array([0.   , 0.875, 1.75 , 2.625, 3.5  , 4.375, 5.25 , 6.125, 7.   ]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(trainer.collect_truth, bins=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step5: visualizing the hidden to output weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "plot_W2 = tsne.fit_transform(trainer.W2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ooo', 'Too', 'oEo', 'ooD', 'TEo', 'ToD', 'oED', 'TED']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"fe10cc92-e367-4f15-8778-072621ef53d0\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"2c98701c-f94c-47e8-976d-79426bae052a\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"1018\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"1013\",\"type\":\"LinearAxis\"},{\"id\":\"1017\",\"type\":\"Grid\"},{\"id\":\"1018\",\"type\":\"LinearAxis\"},{\"id\":\"1022\",\"type\":\"Grid\"},{\"id\":\"1036\",\"type\":\"GlyphRenderer\"},{\"id\":\"1038\",\"type\":\"LabelSet\"}],\"title\":{\"id\":\"1002\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1027\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1005\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1009\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1007\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1011\",\"type\":\"LinearScale\"}},\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"SaveTool\"},{\"attributes\":{\"plot\":null,\"text\":\"word2vec T-SNE for most common words\"},\"id\":\"1002\",\"type\":\"Title\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1023\",\"type\":\"PanTool\"},{\"id\":\"1024\",\"type\":\"WheelZoomTool\"},{\"id\":\"1025\",\"type\":\"ResetTool\"},{\"id\":\"1026\",\"type\":\"SaveTool\"}]},\"id\":\"1027\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data_source\":{\"id\":\"1032\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1034\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1035\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"1037\",\"type\":\"CDSView\"}},\"id\":\"1036\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"1032\",\"type\":\"ColumnDataSource\"}},\"id\":\"1037\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"formatter\":{\"id\":\"1041\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1014\",\"type\":\"BasicTicker\"}},\"id\":\"1013\",\"type\":\"LinearAxis\"},{\"attributes\":{\"plot\":{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"source\":{\"id\":\"1032\",\"type\":\"ColumnDataSource\"},\"text\":{\"field\":\"names\"},\"text_align\":\"center\",\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"},\"y_offset\":{\"value\":6}},\"id\":\"1038\",\"type\":\"LabelSet\"},{\"attributes\":{},\"id\":\"1041\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"plot\":{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1014\",\"type\":\"BasicTicker\"}},\"id\":\"1017\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null,\"data\":{\"names\":[\"ooo\",\"Too\",\"oEo\",\"ooD\",\"TEo\",\"ToD\",\"oED\",\"TED\"],\"x1\":{\"__ndarray__\":\"Yai0QfqLLUK5x25BTxnRQZYRIEK7f35CyEQ/QpCidkI=\",\"dtype\":\"float32\",\"shape\":[8]},\"x2\":{\"__ndarray__\":\"1JqSwn0eoMIiPVPCJhsIwitYXMI1/DjCB/j4we4PiMI=\",\"dtype\":\"float32\",\"shape\":[8]}},\"selected\":{\"id\":\"1045\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1046\",\"type\":\"UnionRenderers\"}},\"id\":\"1032\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1043\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"formatter\":{\"id\":\"1043\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1019\",\"type\":\"BasicTicker\"}},\"id\":\"1018\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1019\",\"type\":\"BasicTicker\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1019\",\"type\":\"BasicTicker\"}},\"id\":\"1022\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"PanTool\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1034\",\"type\":\"Scatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1035\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"Selection\"}],\"root_ids\":[\"1003\"]},\"title\":\"Bokeh Application\",\"version\":\"1.0.2\"}};\n",
       "  var render_items = [{\"docid\":\"2c98701c-f94c-47e8-976d-79426bae052a\",\"roots\":{\"1003\":\"fe10cc92-e367-4f15-8778-072621ef53d0\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1003"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"word2vec T-SNE for most common words\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=plot_W2[:,0],\n",
    "                                    x2=plot_W2[:,1],\n",
    "                                    names=label_lookup))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source)\n",
    "\n",
    "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                  source=source, text_align='center')\n",
    "p.add_layout(labels)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
